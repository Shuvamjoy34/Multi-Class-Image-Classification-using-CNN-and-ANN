{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN Image Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shuvamjoy34/Multi-Class-Image-Classification-using-CNN-and-ANN/blob/main/ANN_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFkuWPYZeO4s"
      },
      "source": [
        "**Bike vs Car vs Random Image Classification using Python,Keras and Artificial Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IwzPSB_5BdE"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten, AveragePooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8pvSilEeZib"
      },
      "source": [
        "**Connecting Google Colab with Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws4O_ErfJ2Dh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOew304Bee28"
      },
      "source": [
        "**Importing the image dataset from google drive and resizing and labelling those images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvMbsJ3t5Pec"
      },
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "car=os.listdir(\"/content/drive/My Drive/Images/car/\")\n",
        "for a in car:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/car/\"+a)\n",
        "        size_image = cv2.resize(image,(128,128)).flatten()\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append('car')\n",
        "    except AttributeError:\n",
        "        print(\"\")\n",
        "\n",
        "bike=os.listdir(\"/content/drive/My Drive/Images/bike/\")\n",
        "for b in bike:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/bike/\"+b)\n",
        "        size_image = cv2.resize(image,(128,128)).flatten()\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append('bike')\n",
        "    except AttributeError:\n",
        "        print(\"\")\n",
        "other=os.listdir(\"/content/drive/My Drive/Images/random/\")\n",
        "for c in other:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/random/\"+c)\n",
        "        size_image = cv2.resize(image,(128,128)).flatten()\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append('others')\n",
        "    except AttributeError:\n",
        "        print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5VbX_iG5tDU"
      },
      "source": [
        "images=np.array(data)\n",
        "labels=np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KuERdWF7C2h"
      },
      "source": [
        "images =images.astype(np.float32)\n",
        "images = images/255\n",
        "\n",
        "train_x , x , train_y , y = train_test_split(images , labels , \n",
        "                                            test_size = 0.2 ,\n",
        "                                            random_state = 111)\n",
        "\n",
        "eval_x , test_x , eval_y , test_y = train_test_split(x , y , \n",
        "                                                    test_size = 0.75 , \n",
        "                                                    random_state = 111)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqGsbD8a_DsY"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "train_y = lb.fit_transform(train_y)\n",
        "test_y = lb.transform(test_y)\n",
        "eval_y = lb.transform(eval_y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QuZ9pYQLquy"
      },
      "source": [
        "from tensorflow.python.keras import regularizers\n",
        "from keras.layers.normalization import BatchNormalization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4D-4aAnDI2k"
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCMvsK9PfUKu"
      },
      "source": [
        "**Optimal Hyper Parameter Search Using Random Search Hyperparameter Optimisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcfGuP8TETea"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def create_model(dropout_rate_opts,learn_rate,momentum,optimizers=\"adam\"):\n",
        "\n",
        "#BasicNNet\n",
        "    model = Sequential()   \n",
        "    model.add(Dense(512, input_shape=(49152,), activation=\"relu\"))\n",
        "#keras.layers.BatchNormalization()             \n",
        "    model.add(Dense(256, activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))) \n",
        "#keras.layers.BatchNormalization()\n",
        "    model.add(Dropout(dropout_rate_opts)) \n",
        "    model.add(Dense(128, activation=\"relu\"))  \n",
        "#keras.layers.BatchNormalization()  \n",
        "    model.add(Dropout(dropout_rate_opts)) \n",
        "    model.add(Dense(64, activation=\"relu\"))  \n",
        "#keras.layers.BatchNormalization()  \n",
        "    model.add(Dropout(dropout_rate_opts)) \n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "#keras.layers.BatchNormalization()\n",
        "    model.add(Dropout(dropout_rate_opts)) \n",
        "    model.add(Dense(16, activation=\"relu\"))\n",
        "#keras.layers.BatchNormalization()\n",
        "    model.add(Dropout(dropout_rate_opts))          \n",
        "    model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
        "    model.summary()\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLFIpj02E55A"
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFU8LZ2WE-UZ",
        "outputId": "fb246d86-528b-4b6f-92ea-cd1516a3e004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "_optimizers=['sgd', 'adam']\n",
        "dropout_rate_opts  = [0,  0.2, 0.3, 0.5]\n",
        "_batch_size=[16,32,64]\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "\n",
        "params=dict(optimizer=_optimizers,\n",
        "            batch_size=_batch_size,\n",
        "            dropout_rate_opts=dropout_rate_opts,\n",
        "            learn_rate=learn_rate,\n",
        "            momentum=momentum\n",
        "            )\n",
        "print(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'optimizer': ['sgd', 'adam'], 'batch_size': [16, 32, 64], 'dropout_rate_opts': [0, 0.2, 0.3, 0.5], 'learn_rate': [0.001, 0.01, 0.1, 0.2, 0.3], 'momentum': [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncmxFdr6FJXS",
        "outputId": "50f62049-a04e-4c4d-cf8f-b4df970a9c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model,epochs=50,batch_size=16)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x7fa6fd4d2cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCshxKVGFgS7",
        "outputId": "54765c6e-9e06-4e1a-de7e-f98647192766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "np.random.seed(42)\n",
        "rscv = RandomizedSearchCV(model, param_distributions=params, cv=3,   n_iter=10)\n",
        "rscv_results = rscv.fit(x,y)\n",
        "print('Best score is: {} using {}'.format(rscv_results.best_score_,\n",
        "rscv_results.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_378 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_379 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_252 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_380 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_253 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_381 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_254 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_382 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_255 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_383 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4669 - accuracy: 0.3846\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.8571 - accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 18.2294 - accuracy: 0.4615\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6335 - accuracy: 0.5385\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.8279 - accuracy: 0.4615\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.8820 - accuracy: 0.4615\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 16.2958 - accuracy: 0.4615\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.6699 - accuracy: 0.6154\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3428 - accuracy: 0.4615\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6500 - accuracy: 0.5385\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6694 - accuracy: 0.6154\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.7531 - accuracy: 0.3846\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.4676 - accuracy: 0.6154\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 17.3132 - accuracy: 0.4615\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0191 - accuracy: 0.5385\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.2337 - accuracy: 0.5385\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.9665 - accuracy: 0.3846\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.5074 - accuracy: 0.3846\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1823 - accuracy: 0.6154\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.7209 - accuracy: 0.4615\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8344 - accuracy: 0.7692\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7560 - accuracy: 0.6154\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.8464 - accuracy: 0.3077\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.2736 - accuracy: 0.6154\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6134 - accuracy: 0.3846\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2376 - accuracy: 0.5385\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.5448 - accuracy: 0.1538\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3786 - accuracy: 0.3846\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4876 - accuracy: 0.4615\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3887 - accuracy: 0.4615\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7740 - accuracy: 0.4615\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1688 - accuracy: 0.4615\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9416 - accuracy: 0.5385\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1663 - accuracy: 0.5385\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3463 - accuracy: 0.3077\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1320 - accuracy: 0.4615\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0723 - accuracy: 0.6923\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4786 - accuracy: 0.3846\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6579 - accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3123 - accuracy: 0.4615\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9990 - accuracy: 0.3846\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9278 - accuracy: 0.3846\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8561 - accuracy: 0.6154\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6441 - accuracy: 0.6923\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2424 - accuracy: 0.3846\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.8478 - accuracy: 0.4615\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5936 - accuracy: 0.5385\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1075 - accuracy: 0.6923\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4647 - accuracy: 0.5385\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4118 - accuracy: 0.5385\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f8f48a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7653 - accuracy: 0.4286\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_384 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_385 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_256 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_386 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_257 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_387 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_258 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_388 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_259 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_389 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3984 - accuracy: 0.6154\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.3816 - accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5524 - accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 16.7927 - accuracy: 0.2308\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.1528 - accuracy: 0.4615\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.5732 - accuracy: 0.4615\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.5256 - accuracy: 0.3846\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.3487 - accuracy: 0.4615\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.4263 - accuracy: 0.4615\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.2007 - accuracy: 0.4615\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5872 - accuracy: 0.5385\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3076 - accuracy: 0.6154\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.5996 - accuracy: 0.3846\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.0638 - accuracy: 0.5385\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.0571 - accuracy: 0.2308\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.2001 - accuracy: 0.3846\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7321 - accuracy: 0.8462\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.4558 - accuracy: 0.5385\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3126 - accuracy: 0.5385\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3464 - accuracy: 0.5385\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6459 - accuracy: 0.4615\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5769 - accuracy: 0.5385\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7469 - accuracy: 0.5385\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0343 - accuracy: 0.4615\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.3027 - accuracy: 0.6154\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.0345 - accuracy: 0.4615\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4380 - accuracy: 0.5385\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.9240 - accuracy: 0.4615\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1061 - accuracy: 0.3077\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7245 - accuracy: 0.6154\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5829 - accuracy: 0.5385\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2482 - accuracy: 0.5385\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3103 - accuracy: 0.3846\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8519 - accuracy: 0.3077\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0338 - accuracy: 0.5385\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7934 - accuracy: 0.5385\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5364 - accuracy: 0.3846\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6045 - accuracy: 0.4615\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4537 - accuracy: 0.6154\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3235 - accuracy: 0.5385\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2455 - accuracy: 0.5385\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4451 - accuracy: 0.5385\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5029 - accuracy: 0.3846\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1471 - accuracy: 0.6154\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2383 - accuracy: 0.3077\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5394 - accuracy: 0.4615\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1658 - accuracy: 0.6923\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6708 - accuracy: 0.5385\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6286 - accuracy: 0.6154\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4671 - accuracy: 0.4615\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f943b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0995 - accuracy: 0.5714\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_390 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_391 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_260 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_392 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_261 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_393 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_262 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_394 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_263 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_395 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7184 - accuracy: 0.2143\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.9859 - accuracy: 0.4286\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 19.5005 - accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.7758 - accuracy: 0.2857\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 20.2552 - accuracy: 0.2143\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.6967 - accuracy: 0.2857\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.4559 - accuracy: 0.4286\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.5120 - accuracy: 0.5714\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.5553 - accuracy: 0.2857\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 16.2123 - accuracy: 0.2143\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.5573 - accuracy: 0.3571\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 14.7519 - accuracy: 0.4286\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.3488 - accuracy: 0.2857\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1883 - accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5674 - accuracy: 0.3571\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4156 - accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5103 - accuracy: 0.4286\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.9796 - accuracy: 0.2857\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7000 - accuracy: 0.3571\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0048 - accuracy: 0.4286\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1325 - accuracy: 0.5714\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0648 - accuracy: 0.3571\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6901 - accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8652 - accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0751 - accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5872 - accuracy: 0.4286\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0822 - accuracy: 0.4286\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3817 - accuracy: 0.2857\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1371 - accuracy: 0.3571\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0756 - accuracy: 0.3571\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9803 - accuracy: 0.2857\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9379 - accuracy: 0.4286\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7678 - accuracy: 0.2857\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5057 - accuracy: 0.7143\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8384 - accuracy: 0.4286\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1287 - accuracy: 0.7857\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5600 - accuracy: 0.5714\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5789 - accuracy: 0.3571\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6741 - accuracy: 0.3571\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5540 - accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5192 - accuracy: 0.2857\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6175 - accuracy: 0.4286\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7453 - accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3079 - accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1206 - accuracy: 0.2857\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3099 - accuracy: 0.6429\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3590 - accuracy: 0.7143\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5457 - accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5490 - accuracy: 0.4286\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9052 - accuracy: 0.4286\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f83ef488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0417 - accuracy: 0.1667\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_396 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_397 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_264 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_398 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_265 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_399 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_266 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_400 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_267 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_401 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3941 - accuracy: 0.3077\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.8139 - accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2878 - accuracy: 0.3077\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.1587 - accuracy: 0.6154\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2764 - accuracy: 0.6154\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5939 - accuracy: 0.0769\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8941 - accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2312 - accuracy: 0.3077\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.9546 - accuracy: 0.6154\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.9897 - accuracy: 0.6154\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8115 - accuracy: 0.6923\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.9454 - accuracy: 0.3077\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8046 - accuracy: 0.3846\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.1304 - accuracy: 0.6154\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.6054 - accuracy: 0.6154\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.8211 - accuracy: 0.6154\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4003 - accuracy: 0.6154\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.2607 - accuracy: 0.3077\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5389 - accuracy: 0.3077\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7311 - accuracy: 0.6154\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7297 - accuracy: 0.6154\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6303 - accuracy: 0.6154\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7394 - accuracy: 0.6154\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1498 - accuracy: 0.3077\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3827 - accuracy: 0.3077\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7423 - accuracy: 0.6923\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6333 - accuracy: 0.5385\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9117 - accuracy: 0.6923\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7396 - accuracy: 0.6923\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7937 - accuracy: 0.6923\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7454 - accuracy: 0.7692\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7636 - accuracy: 0.3077\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8462\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8326 - accuracy: 0.6154\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9074 - accuracy: 0.6923\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8462\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.9231\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.9231\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.9231\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.9231\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f90d18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1550 - accuracy: 0.5714\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_402 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_403 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_268 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_404 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_269 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_405 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_270 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_406 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_271 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_407 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4204 - accuracy: 0.6154\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3976 - accuracy: 0.3077\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 27.1254 - accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 23.4194 - accuracy: 0.6154\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.5930 - accuracy: 0.6154\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.2455 - accuracy: 0.2308\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7065 - accuracy: 0.6154\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9083 - accuracy: 0.6154\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 20.1369 - accuracy: 0.1538\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9158 - accuracy: 0.2308\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4159 - accuracy: 0.6923\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5985 - accuracy: 0.6154\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2092 - accuracy: 0.6154\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7266 - accuracy: 0.2308\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5024 - accuracy: 0.8462\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8309 - accuracy: 0.8462\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9561 - accuracy: 0.5385\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6059 - accuracy: 0.8462\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.9231\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.8462\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.9231\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.9231\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.9231\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.9231\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2548 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f90d6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4160 - accuracy: 0.4286\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_408 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_409 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_272 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_410 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_273 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_411 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_274 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_412 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_275 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_413 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4574 - accuracy: 0.3571\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.5453 - accuracy: 0.4286\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9131 - accuracy: 0.4286\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.6421 - accuracy: 0.2857\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.3764 - accuracy: 0.2857\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4717 - accuracy: 0.2857\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3305 - accuracy: 0.2857\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4865 - accuracy: 0.4286\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7627 - accuracy: 0.4286\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1037 - accuracy: 0.4286\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8209 - accuracy: 0.7143\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2128 - accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7455 - accuracy: 0.8571\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4529 - accuracy: 0.5714\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6374 - accuracy: 0.5714\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8968 - accuracy: 0.5714\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.7143\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0642 - accuracy: 0.7143\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9600 - accuracy: 0.7143\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.9286\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.6429\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7617 - accuracy: 0.6429\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.8571\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.8571\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.8571\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.9286\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2956 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2612 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f7ac5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6667\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_414 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_415 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_276 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_416 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_277 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_417 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_278 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_418 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_279 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_419 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4758 - accuracy: 0.2308\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4936 - accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 32.7475 - accuracy: 0.3077\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6116 - accuracy: 0.6923\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.5326 - accuracy: 0.3077\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 24.7893 - accuracy: 0.0769\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 23.7750 - accuracy: 0.6154\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.0541 - accuracy: 0.6154\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 16.3796 - accuracy: 0.6154\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2929 - accuracy: 0.6154\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.9458 - accuracy: 0.3077\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.7123 - accuracy: 0.3077\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9783 - accuracy: 0.6923\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9003 - accuracy: 0.6923\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8115 - accuracy: 0.6154\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7694 - accuracy: 0.7692\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9096 - accuracy: 0.5385\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0914 - accuracy: 0.0769\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6330 - accuracy: 0.6154\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7732 - accuracy: 0.6154\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2940 - accuracy: 0.3846\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0146 - accuracy: 0.9231\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2695 - accuracy: 0.7692\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5222 - accuracy: 0.6154\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7787 - accuracy: 0.9231\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5483 - accuracy: 0.8462\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9715 - accuracy: 0.8462\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0934 - accuracy: 0.9231\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9405 - accuracy: 0.3077\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8386 - accuracy: 0.9231\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2240 - accuracy: 0.9231\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3973 - accuracy: 0.9231\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3701 - accuracy: 0.9231\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1698 - accuracy: 0.9231\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8641 - accuracy: 0.8462\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.9231\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.8462\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.9231\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.9231\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.9231\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f78e89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1374 - accuracy: 0.4286\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_420 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_421 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_280 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_422 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_281 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_423 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_282 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_424 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_283 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_425 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5817 - accuracy: 0.1538\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.6620 - accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2180 - accuracy: 0.2308\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1810 - accuracy: 0.6154\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.8821 - accuracy: 0.1538\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6907 - accuracy: 0.1538\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.2983 - accuracy: 0.6154\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6186 - accuracy: 0.6154\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.4076 - accuracy: 0.2308\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0445 - accuracy: 0.6154\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6391 - accuracy: 0.6154\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7935 - accuracy: 0.2308\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8612 - accuracy: 0.6154\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6223 - accuracy: 0.6154\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7810 - accuracy: 0.8462\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9971 - accuracy: 0.3846\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.9231\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3776 - accuracy: 0.6154\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8670 - accuracy: 0.8462\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.8462\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.8462\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.9231\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7692\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.9231\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.8462\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8462\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1772 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f2d69378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2836 - accuracy: 0.2857\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_426 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_427 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_284 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_428 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_285 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_429 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_286 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_430 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_287 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_431 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5393 - accuracy: 0.4286\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.6808 - accuracy: 0.2857\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 39.2780 - accuracy: 0.4286\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.3159 - accuracy: 0.2857\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.1990 - accuracy: 0.2857\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6334 - accuracy: 0.4286\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1534 - accuracy: 0.2857\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6023 - accuracy: 0.3571\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7915 - accuracy: 0.4286\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0705 - accuracy: 0.3571\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8359 - accuracy: 0.5714\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8914 - accuracy: 0.7143\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7181 - accuracy: 0.7857\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1568 - accuracy: 0.5714\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.9286\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2668 - accuracy: 0.7143\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4557 - accuracy: 0.6429\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.9286\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5167 - accuracy: 0.3571\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7857\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0678 - accuracy: 0.7143\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9650 - accuracy: 0.6429\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.8571\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.7857\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8571\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1174 - accuracy: 0.7143\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.9286\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7190 - accuracy: 0.7857\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.9286\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f7ffcf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.1910 - accuracy: 0.6667\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_432 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_433 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_288 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_434 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_289 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_435 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_290 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_436 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_291 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_437 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3985 - accuracy: 0.2308\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 34.3989 - accuracy: 0.3077\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 48.9689 - accuracy: 0.3077\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 30.2584 - accuracy: 0.3846\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 56.9720 - accuracy: 0.2308\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 43.3953 - accuracy: 0.2308\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 79.5785 - accuracy: 0.2308\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 44.3494 - accuracy: 0.3077\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 37.5900 - accuracy: 0.4615\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 36.2067 - accuracy: 0.3077\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 19.4294 - accuracy: 0.6923\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 36.9169 - accuracy: 0.6154\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 68.0969 - accuracy: 0.3077\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 50.1122 - accuracy: 0.4615\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 25.4594 - accuracy: 0.5385\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.2832 - accuracy: 0.3846\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.0362 - accuracy: 0.4615\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 37.1839 - accuracy: 0.3077\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.1365 - accuracy: 0.4615\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 33.9429 - accuracy: 0.4615\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 21.1607 - accuracy: 0.3846\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.5513 - accuracy: 0.6923\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 25.1740 - accuracy: 0.6154\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 47.5411 - accuracy: 0.3077\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 31.1040 - accuracy: 0.4615\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 22.1576 - accuracy: 0.5385\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 38.1482 - accuracy: 0.3077\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.8100 - accuracy: 0.4615\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 30.6418 - accuracy: 0.4615\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5613 - accuracy: 0.5385\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.5519 - accuracy: 0.3846\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.9167 - accuracy: 0.3846\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 23.3520 - accuracy: 0.3077\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.9953 - accuracy: 0.3846\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 28.0416 - accuracy: 0.0769\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5044 - accuracy: 0.5385\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.5727 - accuracy: 0.5385\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6962 - accuracy: 0.4615\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.1635 - accuracy: 0.3846\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 23.3265 - accuracy: 0.2308\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5568 - accuracy: 0.4615\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7153 - accuracy: 0.6154\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.2742 - accuracy: 0.3077\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.3873 - accuracy: 0.3077\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9787 - accuracy: 0.3846\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7974 - accuracy: 0.1538\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7242 - accuracy: 0.3077\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7246 - accuracy: 0.3846\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.6736 - accuracy: 0.2308\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7323 - accuracy: 0.6154\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f90d66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6854 - accuracy: 0.4286\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_438 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_439 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_292 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_440 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_293 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_441 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_294 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_442 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_295 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_443 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6621 - accuracy: 0.3846\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 23.3717 - accuracy: 0.4615\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.8586 - accuracy: 0.3077\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 58.7017 - accuracy: 0.1538\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 43.4446 - accuracy: 0.1538\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 47.4663 - accuracy: 0.5385\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 48.3007 - accuracy: 0.3077\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 27.9802 - accuracy: 0.3846\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 83.4116 - accuracy: 0.3077\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 55.1376 - accuracy: 0.3846\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 39.2925 - accuracy: 0.3846\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 63.8433 - accuracy: 0.2308\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 69.0911 - accuracy: 0.2308\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 31.8946 - accuracy: 0.3846\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 53.4415 - accuracy: 0.3846\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 31.5138 - accuracy: 0.3077\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 26.4011 - accuracy: 0.3846\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 31.1817 - accuracy: 0.2308\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 28.4594 - accuracy: 0.5385\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 35.3278 - accuracy: 0.0769\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.6947 - accuracy: 0.3846\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 55.6939 - accuracy: 0.1538\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 22.1468 - accuracy: 0.4615\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 22.6392 - accuracy: 0.3077\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 33.9502 - accuracy: 0.2308\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.6109 - accuracy: 0.4615\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.1371 - accuracy: 0.3077\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 20.0479 - accuracy: 0.3077\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 25.5798 - accuracy: 0.2308\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 26.3124 - accuracy: 0.4615\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.8902 - accuracy: 0.6923\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.8545 - accuracy: 0.6154\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.4928 - accuracy: 0.4615\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.2827 - accuracy: 0.3077\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9518 - accuracy: 0.3846\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5627 - accuracy: 0.5385\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.3800 - accuracy: 0.4615\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.4379 - accuracy: 0.3846\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.2135 - accuracy: 0.3846\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8410 - accuracy: 0.3846\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7771 - accuracy: 0.3846\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.0741 - accuracy: 0.1538\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3424 - accuracy: 0.3077\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8179 - accuracy: 0.2308\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.2028 - accuracy: 0.3846\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.9210 - accuracy: 0.2308\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.6719 - accuracy: 0.3077\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3784 - accuracy: 0.3846\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7141 - accuracy: 0.3077\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.2931 - accuracy: 0.3077\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f7be7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6433 - accuracy: 0.4286\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_444 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_445 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_296 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_446 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_297 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_447 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_298 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_448 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_299 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_449 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5472 - accuracy: 0.3571\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 48.8186 - accuracy: 0.2143\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 44.8844 - accuracy: 0.3571\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 51.0310 - accuracy: 0.4286\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 57.8118 - accuracy: 0.4286\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 45.7292 - accuracy: 0.4286\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 93.0086 - accuracy: 0.2143\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 73.3156 - accuracy: 0.0714\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 34.9441 - accuracy: 0.4286\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 42.8158 - accuracy: 0.1429\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 48.9578 - accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 37.7120 - accuracy: 0.4286\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 42.7623 - accuracy: 0.4286\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 29.9983 - accuracy: 0.4286\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 57.2993 - accuracy: 0.2857\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 42.7356 - accuracy: 0.1429\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 38.2945 - accuracy: 0.1429\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 60.6650 - accuracy: 0.1429\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 31.6210 - accuracy: 0.4286\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.0393 - accuracy: 0.3571\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 28.5767 - accuracy: 0.2857\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 36.7712 - accuracy: 0.2857\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 40.6954 - accuracy: 0.4286\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 30.4735 - accuracy: 0.2143\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 18.7097 - accuracy: 0.2857\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 21.4749 - accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 20.8988 - accuracy: 0.2857\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.5128 - accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 21.2914 - accuracy: 0.2857\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.0073 - accuracy: 0.3571\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 27.9843 - accuracy: 0.2143\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 21.5838 - accuracy: 0.4286\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.9902 - accuracy: 0.3571\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.4084 - accuracy: 0.4286\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.8531 - accuracy: 0.3571\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5184 - accuracy: 0.3571\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 12.3193 - accuracy: 0.3571\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9356 - accuracy: 0.4286\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5388 - accuracy: 0.3571\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5376 - accuracy: 0.4286\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1623 - accuracy: 0.4286\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9706 - accuracy: 0.2143\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8828 - accuracy: 0.3571\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.4741 - accuracy: 0.2143\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0986 - accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3819 - accuracy: 0.3571\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.0599 - accuracy: 0.2143\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6845 - accuracy: 0.3571\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3690 - accuracy: 0.3571\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.5934 - accuracy: 0.2857\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f80f26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6305 - accuracy: 0.0000e+00\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_450 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_451 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_300 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_452 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_301 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_453 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_302 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_454 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_303 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_455 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6783 - accuracy: 0.5385\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 28.6243 - accuracy: 0.4615\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 27.0016 - accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 55.2135 - accuracy: 0.3846\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 63.9789 - accuracy: 0.5385\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 29.5949 - accuracy: 0.6154\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 29.4711 - accuracy: 0.4615\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 80.8125 - accuracy: 0.3077\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 30.1634 - accuracy: 0.3846\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 48.0501 - accuracy: 0.6923\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 25.0062 - accuracy: 0.3846\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 40.8562 - accuracy: 0.6154\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 42.4603 - accuracy: 0.4615\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.8040 - accuracy: 0.3846\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 22.4898 - accuracy: 0.6154\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 31.6424 - accuracy: 0.4615\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 24.1650 - accuracy: 0.3846\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 27.4611 - accuracy: 0.3846\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 24.2169 - accuracy: 0.6154\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 16.6866 - accuracy: 0.3846\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.1717 - accuracy: 0.4615\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.1122 - accuracy: 0.6923\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 38.9679 - accuracy: 0.3077\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.7966 - accuracy: 0.5385\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 16.8146 - accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.6458 - accuracy: 0.6154\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.7639 - accuracy: 0.4615\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 21.6766 - accuracy: 0.0769\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0073 - accuracy: 0.6154\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2729 - accuracy: 0.5385\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.2400 - accuracy: 0.5385\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.6056 - accuracy: 0.5385\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.7963 - accuracy: 0.5385\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 14.5666 - accuracy: 0.4615\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 22.9332 - accuracy: 0.3077\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 17.0014 - accuracy: 0.1538\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 20.0288 - accuracy: 0.3846\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.0478 - accuracy: 0.5385\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4795 - accuracy: 0.5385\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5424 - accuracy: 0.4615\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.5810 - accuracy: 0.3846\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4104 - accuracy: 0.3846\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0691 - accuracy: 0.5385\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6517 - accuracy: 0.5385\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8680 - accuracy: 0.5385\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6551 - accuracy: 0.3846\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5963 - accuracy: 0.6154\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7375 - accuracy: 0.4615\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4203 - accuracy: 0.3077\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9068 - accuracy: 0.3077\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f829f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6823 - accuracy: 0.1429\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_456 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_457 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_304 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_458 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_305 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_459 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_306 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_460 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_307 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_461 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3962 - accuracy: 0.2308\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 16.6680 - accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 63.1333 - accuracy: 0.2308\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 56.9485 - accuracy: 0.4615\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 64.9942 - accuracy: 0.0769\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 50.1597 - accuracy: 0.3077\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 22.7613 - accuracy: 0.5385\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 62.4713 - accuracy: 0.4615\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 67.2576 - accuracy: 0.1538\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 80.6638 - accuracy: 0.2308\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 71.7551 - accuracy: 0.3846\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 66.5912 - accuracy: 0.2308\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 41.5288 - accuracy: 0.4615\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 73.4897 - accuracy: 0.0769\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 52.8321 - accuracy: 0.2308\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 46.4961 - accuracy: 0.3846\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 37.7940 - accuracy: 0.2308\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 28.5232 - accuracy: 0.3846\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 45.4565 - accuracy: 0.2308\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 38.4008 - accuracy: 0.4615\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 35.1574 - accuracy: 0.2308\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 35.6026 - accuracy: 0.1538\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.3187 - accuracy: 0.3846\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2056 - accuracy: 0.6923\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9290 - accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.0546 - accuracy: 0.3077\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 27.2755 - accuracy: 0.2308\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.0987 - accuracy: 0.3846\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.9713 - accuracy: 0.2308\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3391 - accuracy: 0.1538\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.3849 - accuracy: 0.2308\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.0905 - accuracy: 0.1538\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.4791 - accuracy: 0.3077\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 13.4628 - accuracy: 0.4615\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5057 - accuracy: 0.5385\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1476 - accuracy: 0.3077\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.1061 - accuracy: 0.3077\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1644 - accuracy: 0.3077\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.2294 - accuracy: 0.3846\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.8128 - accuracy: 0.2308\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.9362 - accuracy: 0.4615\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.5907 - accuracy: 0.3077\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9386 - accuracy: 0.5385\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.2743 - accuracy: 0.3077\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4748 - accuracy: 0.4615\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5842 - accuracy: 0.3077\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5536 - accuracy: 0.4615\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2229 - accuracy: 0.6154\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.2703 - accuracy: 0.3846\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.1672 - accuracy: 0.3077\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f9318ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1973 - accuracy: 0.4286\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_462 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_463 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_308 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_464 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_309 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_465 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_310 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_466 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_311 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_467 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1075 - accuracy: 0.4286\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 30.3739 - accuracy: 0.4286\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 54.9819 - accuracy: 0.2857\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 67.2021 - accuracy: 0.4286\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 55.1439 - accuracy: 0.2857\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 51.2186 - accuracy: 0.2857\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 53.2902 - accuracy: 0.2857\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 51.2661 - accuracy: 0.2857\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.8083 - accuracy: 0.3571\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 36.0272 - accuracy: 0.3571\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 39.5439 - accuracy: 0.4286\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 34.6525 - accuracy: 0.3571\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 46.3974 - accuracy: 0.2143\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 41.7298 - accuracy: 0.2143\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 37.2730 - accuracy: 0.4286\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 32.7931 - accuracy: 0.3571\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 41.5706 - accuracy: 0.3571\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.7164 - accuracy: 0.5714\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 23.1403 - accuracy: 0.2143\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.8431 - accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.8011 - accuracy: 0.4286\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 16.0522 - accuracy: 0.3571\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.9949 - accuracy: 0.4286\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.0920 - accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 20.0211 - accuracy: 0.3571\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 31.6911 - accuracy: 0.1429\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.7328 - accuracy: 0.4286\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.3896 - accuracy: 0.3571\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.8304 - accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.2764 - accuracy: 0.2143\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.4461 - accuracy: 0.2857\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.6519 - accuracy: 0.1429\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.6084 - accuracy: 0.2143\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.7030 - accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 17.9717 - accuracy: 0.2857\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.2047 - accuracy: 0.1429\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.9712 - accuracy: 0.3571\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.9149 - accuracy: 0.2143\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3778 - accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.2265 - accuracy: 0.2143\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.9171 - accuracy: 0.2857\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.0274 - accuracy: 0.4286\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.2764 - accuracy: 0.3571\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9409 - accuracy: 0.4286\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.7257 - accuracy: 0.2143\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7089 - accuracy: 0.1429\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7620 - accuracy: 0.2143\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5901 - accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5953 - accuracy: 0.3571\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7233 - accuracy: 0.4286\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f3d34840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3341 - accuracy: 0.1667\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_468 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_469 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_312 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_470 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_313 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_471 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_314 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_472 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_315 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_473 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4001 - accuracy: 0.4615\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9439 - accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.7849 - accuracy: 0.3077\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.6337 - accuracy: 0.3846\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.6795 - accuracy: 0.5385\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.9956 - accuracy: 0.3077\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.0711 - accuracy: 0.3077\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.6153 - accuracy: 0.4615\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7624 - accuracy: 0.3846\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2201 - accuracy: 0.4615\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0850 - accuracy: 0.5385\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.5922 - accuracy: 0.4615\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7712 - accuracy: 0.6154\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6898 - accuracy: 0.6154\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0516 - accuracy: 0.6923\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9718 - accuracy: 0.3846\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2352 - accuracy: 0.6923\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1016 - accuracy: 0.5385\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.8688 - accuracy: 0.3077\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5519 - accuracy: 0.4615\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9227 - accuracy: 0.5385\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8902 - accuracy: 0.3846\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4909 - accuracy: 0.7692\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4782 - accuracy: 0.3846\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6606 - accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3580 - accuracy: 0.7692\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5860 - accuracy: 0.4615\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9235 - accuracy: 0.5385\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9765 - accuracy: 0.6923\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6034 - accuracy: 0.6154\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3647 - accuracy: 0.6923\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.5384 - accuracy: 0.4615\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9581 - accuracy: 0.6923\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6805 - accuracy: 0.5385\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2116 - accuracy: 0.3846\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3433 - accuracy: 0.4615\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9111 - accuracy: 0.4615\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2979 - accuracy: 0.6923\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6333 - accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2314 - accuracy: 0.5385\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5636 - accuracy: 0.4615\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1474 - accuracy: 0.5385\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1861 - accuracy: 0.3846\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6809 - accuracy: 0.6154\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1877 - accuracy: 0.4615\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2510 - accuracy: 0.6923\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5130 - accuracy: 0.6923\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6452 - accuracy: 0.6154\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2094 - accuracy: 0.6154\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0170 - accuracy: 0.4615\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f3b002f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9903 - accuracy: 0.4286\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_474 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_475 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_316 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_476 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_317 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_477 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_318 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_478 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_319 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_479 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6971 - accuracy: 0.1538\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5225 - accuracy: 0.3077\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.5756 - accuracy: 0.3846\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.3386 - accuracy: 0.6154\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.1367 - accuracy: 0.3846\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.1424 - accuracy: 0.4615\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5044 - accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 21.7697 - accuracy: 0.0769\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9685 - accuracy: 0.5385\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 23.5286 - accuracy: 0.3077\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.0431 - accuracy: 0.6154\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3246 - accuracy: 0.3077\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.6280 - accuracy: 0.3846\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.0305 - accuracy: 0.4615\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8075 - accuracy: 0.5385\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.8854 - accuracy: 0.3846\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.9851 - accuracy: 0.3846\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6595 - accuracy: 0.3077\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3495 - accuracy: 0.3846\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3931 - accuracy: 0.2308\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2451 - accuracy: 0.4615\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8650 - accuracy: 0.4615\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2314 - accuracy: 0.4615\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6281 - accuracy: 0.5385\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2803 - accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6302 - accuracy: 0.7692\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3760 - accuracy: 0.4615\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9004 - accuracy: 0.5385\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8223 - accuracy: 0.5385\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6106 - accuracy: 0.4615\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2445 - accuracy: 0.3846\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7368 - accuracy: 0.3846\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9262 - accuracy: 0.4615\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8544 - accuracy: 0.7692\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2776 - accuracy: 0.5385\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0194 - accuracy: 0.6923\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4621 - accuracy: 0.6154\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6790 - accuracy: 0.6154\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1114 - accuracy: 0.7692\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6970 - accuracy: 0.5385\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3522 - accuracy: 0.7692\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1441 - accuracy: 0.6154\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9600 - accuracy: 0.6923\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2934 - accuracy: 0.5385\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7170 - accuracy: 0.6154\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9135 - accuracy: 0.6154\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0538 - accuracy: 0.7692\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7532 - accuracy: 0.6154\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0035 - accuracy: 0.5385\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1580 - accuracy: 0.6923\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f38fca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4696 - accuracy: 0.4286\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_480 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_481 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_320 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_482 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_321 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_483 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_322 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_484 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_323 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_485 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7587 - accuracy: 0.2857\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.7810 - accuracy: 0.2857\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.9998 - accuracy: 0.2857\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.4066 - accuracy: 0.2143\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.8089 - accuracy: 0.4286\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 21.6895 - accuracy: 0.2143\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.3731 - accuracy: 0.3571\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.9874 - accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.8387 - accuracy: 0.4286\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.1681 - accuracy: 0.3571\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7143 - accuracy: 0.5714\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.2844 - accuracy: 0.3571\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 18.1817 - accuracy: 0.2857\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3182 - accuracy: 0.5714\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7800 - accuracy: 0.4286\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.1452 - accuracy: 0.4286\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.9223 - accuracy: 0.3571\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2201 - accuracy: 0.3571\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8824 - accuracy: 0.3571\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.8831 - accuracy: 0.4286\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.0560 - accuracy: 0.3571\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6865 - accuracy: 0.3571\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8814 - accuracy: 0.2857\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.0309 - accuracy: 0.2143\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9778 - accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6560 - accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7404 - accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3399 - accuracy: 0.3571\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5663 - accuracy: 0.5714\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2673 - accuracy: 0.3571\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7721 - accuracy: 0.5714\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4201 - accuracy: 0.6429\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8426 - accuracy: 0.5714\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5155 - accuracy: 0.3571\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0572 - accuracy: 0.4286\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7716 - accuracy: 0.4286\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9878 - accuracy: 0.5714\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9349 - accuracy: 0.7143\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9738 - accuracy: 0.1429\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8746 - accuracy: 0.3571\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2060 - accuracy: 0.4286\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5469 - accuracy: 0.4286\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1670 - accuracy: 0.4286\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1438 - accuracy: 0.2857\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9733 - accuracy: 0.6429\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2111 - accuracy: 0.3571\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0595 - accuracy: 0.2857\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8268 - accuracy: 0.3571\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8873 - accuracy: 0.1429\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5654 - accuracy: 0.5714\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f7809158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.8333\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_486 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_487 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_324 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_488 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_325 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_489 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_326 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_490 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_327 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_491 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4676 - accuracy: 0.5385\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.8454 - accuracy: 0.5385\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.1956 - accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5624 - accuracy: 0.4615\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.8852 - accuracy: 0.4615\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.1587 - accuracy: 0.4615\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 17.9723 - accuracy: 0.4615\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.2415 - accuracy: 0.4615\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.6397 - accuracy: 0.3077\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8572 - accuracy: 0.6923\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.5862 - accuracy: 0.3846\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.2983 - accuracy: 0.4615\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.5798 - accuracy: 0.7692\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0494 - accuracy: 0.4615\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8290 - accuracy: 0.3846\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 18.4227 - accuracy: 0.1538\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.2649 - accuracy: 0.5385\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.0117 - accuracy: 0.4615\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6535 - accuracy: 0.3846\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7666 - accuracy: 0.4615\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.9857 - accuracy: 0.4615\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.8863 - accuracy: 0.1538\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.0545 - accuracy: 0.3077\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3234 - accuracy: 0.2308\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3019 - accuracy: 0.3846\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0261 - accuracy: 0.5385\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5071 - accuracy: 0.5385\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8439 - accuracy: 0.4615\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4205 - accuracy: 0.6923\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5349 - accuracy: 0.6154\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9245 - accuracy: 0.6923\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4850 - accuracy: 0.6154\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3667 - accuracy: 0.5385\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1928 - accuracy: 0.5385\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3937 - accuracy: 0.6923\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0021 - accuracy: 0.5385\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9671 - accuracy: 0.6154\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5175 - accuracy: 0.5385\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0484 - accuracy: 0.3846\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9645 - accuracy: 0.5385\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6188 - accuracy: 0.6154\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4786 - accuracy: 0.5385\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3207 - accuracy: 0.6154\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7813 - accuracy: 0.4615\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0397 - accuracy: 0.6154\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1794 - accuracy: 0.6923\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0493 - accuracy: 0.4615\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5650 - accuracy: 0.4615\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9063 - accuracy: 0.4615\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5895 - accuracy: 0.6923\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f7882d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1500 - accuracy: 0.5714\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_492 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_493 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_328 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_494 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_329 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_495 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_330 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_496 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_331 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_497 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5585 - accuracy: 0.1538\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6678 - accuracy: 0.2308\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8742 - accuracy: 0.7692\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 23.0559 - accuracy: 0.4615\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 18.1919 - accuracy: 0.4615\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.7699 - accuracy: 0.3846\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 22.6803 - accuracy: 0.3077\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 24.3479 - accuracy: 0.5385\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 27.2039 - accuracy: 0.4615\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7120 - accuracy: 0.6923\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.8658 - accuracy: 0.5385\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.4089 - accuracy: 0.3077\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.1037 - accuracy: 0.3077\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0849 - accuracy: 0.5385\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1182 - accuracy: 0.5385\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7816 - accuracy: 0.4615\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3617 - accuracy: 0.4615\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8939 - accuracy: 0.4615\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9591 - accuracy: 0.3846\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6538 - accuracy: 0.5385\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.6608 - accuracy: 0.1538\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5425 - accuracy: 0.3846\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5162 - accuracy: 0.6923\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2194 - accuracy: 0.6154\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8452 - accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3827 - accuracy: 0.4615\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.7028 - accuracy: 0.5385\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0029 - accuracy: 0.5385\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8213 - accuracy: 0.4615\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7231 - accuracy: 0.4615\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0976 - accuracy: 0.3846\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4794 - accuracy: 0.5385\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0384 - accuracy: 0.5385\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5924 - accuracy: 0.3077\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7642 - accuracy: 0.6154\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3866 - accuracy: 0.6154\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.2782 - accuracy: 0.4615\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2187 - accuracy: 0.6154\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3621 - accuracy: 0.6154\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5130 - accuracy: 0.6154\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5127 - accuracy: 0.5385\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1371 - accuracy: 0.4615\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3256 - accuracy: 0.6154\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2484 - accuracy: 0.6154\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7182 - accuracy: 0.3077\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0993 - accuracy: 0.4615\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9675 - accuracy: 0.3846\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9629 - accuracy: 0.5385\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2500 - accuracy: 0.6923\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4335 - accuracy: 0.5385\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f7c15bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.5955 - accuracy: 0.4286\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_498 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_499 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_332 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_500 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_333 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_501 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_334 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_502 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_335 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_503 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8275 - accuracy: 0.2857\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.7153 - accuracy: 0.2857\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.8478 - accuracy: 0.4286\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 25.2459 - accuracy: 0.0714\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2834 - accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.5505 - accuracy: 0.4286\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6729 - accuracy: 0.4286\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.1361 - accuracy: 0.3571\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.9338 - accuracy: 0.2143\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.3623 - accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.9514 - accuracy: 0.2857\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.4720 - accuracy: 0.3571\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 14.5813 - accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.9137 - accuracy: 0.3571\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.5694 - accuracy: 0.4286\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4127 - accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.1033 - accuracy: 0.3571\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.6567 - accuracy: 0.3571\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 16.5873 - accuracy: 0.1429\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5786 - accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5464 - accuracy: 0.5714\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4166 - accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1246 - accuracy: 0.2857\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9387 - accuracy: 0.4286\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8492 - accuracy: 0.6429\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6322 - accuracy: 0.2857\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7884 - accuracy: 0.3571\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9934 - accuracy: 0.7143\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6114 - accuracy: 0.2857\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9633 - accuracy: 0.4286\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3417 - accuracy: 0.6429\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8380 - accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3060 - accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7322 - accuracy: 0.5714\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0930 - accuracy: 0.8571\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4014 - accuracy: 0.5714\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4805 - accuracy: 0.5714\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0066 - accuracy: 0.4286\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5483 - accuracy: 0.5714\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2404 - accuracy: 0.6429\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9467 - accuracy: 0.7143\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1818 - accuracy: 0.6429\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1001 - accuracy: 0.5714\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7322 - accuracy: 0.5714\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5544 - accuracy: 0.6429\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2227 - accuracy: 0.7143\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8662 - accuracy: 0.4286\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4792 - accuracy: 0.8571\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7491 - accuracy: 0.5714\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1771 - accuracy: 0.7143\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f82f9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7905 - accuracy: 0.8333\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_504 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_505 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_336 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_506 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_337 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_507 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_338 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_508 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_339 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_509 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3327 - accuracy: 0.5385\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.1213 - accuracy: 0.4615\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.1544 - accuracy: 0.4615\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 22.7024 - accuracy: 0.4615\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 35.6448 - accuracy: 0.6154\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 14.8442 - accuracy: 0.6154\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.1410 - accuracy: 0.4615\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 20.0490 - accuracy: 0.4615\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 37.7961 - accuracy: 0.3077\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.9319 - accuracy: 0.5385\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 29.8730 - accuracy: 0.5385\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 38.9179 - accuracy: 0.3846\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 20.3291 - accuracy: 0.4615\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2956 - accuracy: 0.6154\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.3592 - accuracy: 0.5385\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3074 - accuracy: 0.6923\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.4177 - accuracy: 0.5385\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.3929 - accuracy: 0.5385\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.2870 - accuracy: 0.5385\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0661 - accuracy: 0.6154\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.6788 - accuracy: 0.3846\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.7571 - accuracy: 0.3846\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.9978 - accuracy: 0.4615\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8894 - accuracy: 0.5385\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.1656 - accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.3490 - accuracy: 0.5385\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.1533 - accuracy: 0.4615\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.7915 - accuracy: 0.3077\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5691 - accuracy: 0.6923\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7647 - accuracy: 0.5385\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7574 - accuracy: 0.5385\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3621 - accuracy: 0.6154\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.5254 - accuracy: 0.3077\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4643 - accuracy: 0.4615\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8800 - accuracy: 0.6154\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7143 - accuracy: 0.3077\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9046 - accuracy: 0.5385\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.2900 - accuracy: 0.3846\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1150 - accuracy: 0.6923\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.8209 - accuracy: 0.2308\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6705 - accuracy: 0.5385\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0031 - accuracy: 0.5385\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1188 - accuracy: 0.3846\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6795 - accuracy: 0.5385\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3463 - accuracy: 0.6154\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3226 - accuracy: 0.6154\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1108 - accuracy: 0.6923\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1531 - accuracy: 0.3846\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3281 - accuracy: 0.6154\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0198 - accuracy: 0.7692\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f85fc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0779 - accuracy: 0.1429\n",
            "Model: \"sequential_85\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_510 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_511 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_340 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_512 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_341 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_513 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_342 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_514 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_343 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_515 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9203 - accuracy: 0.2308\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.4430 - accuracy: 0.1538\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.2255 - accuracy: 0.3077\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 23.1028 - accuracy: 0.2308\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 26.3665 - accuracy: 0.3846\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 24.1010 - accuracy: 0.3846\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 26.2270 - accuracy: 0.4615\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 22.6550 - accuracy: 0.3846\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 24.4308 - accuracy: 0.4615\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 27.1245 - accuracy: 0.3077\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.6881 - accuracy: 0.2308\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 24.7638 - accuracy: 0.3846\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.6203 - accuracy: 0.4615\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7866 - accuracy: 0.6154\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 26.2941 - accuracy: 0.3846\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 14.8285 - accuracy: 0.1538\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.7890 - accuracy: 0.3846\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.4459 - accuracy: 0.3846\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 31.8117 - accuracy: 0.2308\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.1342 - accuracy: 0.3846\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.6959 - accuracy: 0.3077\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 14.2374 - accuracy: 0.3846\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.1399 - accuracy: 0.6154\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.1528 - accuracy: 0.3846\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.6099 - accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9074 - accuracy: 0.3846\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3063 - accuracy: 0.6154\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9511 - accuracy: 0.4615\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7422 - accuracy: 0.6154\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6535 - accuracy: 0.4615\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5096 - accuracy: 0.3846\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.2992 - accuracy: 0.3077\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7393 - accuracy: 0.3846\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9877 - accuracy: 0.4615\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0420 - accuracy: 0.6154\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8793 - accuracy: 0.6154\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7071 - accuracy: 0.6154\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3840 - accuracy: 0.3077\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0696 - accuracy: 0.3846\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4138 - accuracy: 0.3077\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5395 - accuracy: 0.5385\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3008 - accuracy: 0.6154\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8430 - accuracy: 0.6154\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6166 - accuracy: 0.6154\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3952 - accuracy: 0.3846\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6958 - accuracy: 0.3077\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9732 - accuracy: 0.1538\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9523 - accuracy: 0.3846\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0092 - accuracy: 0.6923\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8167 - accuracy: 0.5385\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f7796f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1051 - accuracy: 0.4286\n",
            "Model: \"sequential_86\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_516 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_517 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_344 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_518 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_345 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_519 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_346 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_520 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_347 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_521 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8416 - accuracy: 0.2143\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.1129 - accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.2577 - accuracy: 0.4286\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.1323 - accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 19.3784 - accuracy: 0.4286\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 29.1641 - accuracy: 0.2857\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 21.5497 - accuracy: 0.3571\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 35.2076 - accuracy: 0.3571\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 37.2543 - accuracy: 0.1429\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 22.2751 - accuracy: 0.3571\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 20.2678 - accuracy: 0.3571\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.1876 - accuracy: 0.5714\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 29.4853 - accuracy: 0.1429\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.4043 - accuracy: 0.2857\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.4918 - accuracy: 0.2857\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 18.9305 - accuracy: 0.3571\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 18.3886 - accuracy: 0.3571\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.6648 - accuracy: 0.2857\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1239 - accuracy: 0.2857\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.9111 - accuracy: 0.2857\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 20.6811 - accuracy: 0.3571\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.7012 - accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.3874 - accuracy: 0.2857\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 14.6492 - accuracy: 0.3571\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.2659 - accuracy: 0.2143\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.8630 - accuracy: 0.2857\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1752 - accuracy: 0.3571\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0541 - accuracy: 0.2143\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7317 - accuracy: 0.2143\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0613 - accuracy: 0.3571\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1022 - accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4756 - accuracy: 0.3571\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7525 - accuracy: 0.7857\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6486 - accuracy: 0.4286\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6679 - accuracy: 0.2143\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5562 - accuracy: 0.3571\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.1085 - accuracy: 0.2857\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2672 - accuracy: 0.2857\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7891 - accuracy: 0.4286\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6095 - accuracy: 0.1429\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0393 - accuracy: 0.2857\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7515 - accuracy: 0.6429\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4203 - accuracy: 0.1429\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2867 - accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2356 - accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7334 - accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5670 - accuracy: 0.5714\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6991 - accuracy: 0.5714\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3932 - accuracy: 0.7857\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1671 - accuracy: 0.6429\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f3c27e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.8333\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_522 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_523 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_348 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_524 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_349 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_525 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_350 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_526 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_351 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_527 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5710 - accuracy: 0.2308\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3305 - accuracy: 0.7692\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.8255 - accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 26.8839 - accuracy: 0.0769\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2005 - accuracy: 0.3077\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6954 - accuracy: 0.6154\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.5696 - accuracy: 0.6154\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9735 - accuracy: 0.6154\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7525 - accuracy: 0.8462\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.5694 - accuracy: 0.3077\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.9231\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7636 - accuracy: 0.0769\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2520 - accuracy: 0.6154\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3763 - accuracy: 0.9231\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1145 - accuracy: 0.3846\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7505 - accuracy: 0.9231\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2466 - accuracy: 0.6923\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7861 - accuracy: 0.9231\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.9231\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.8462\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.9231\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.9231\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.9231\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0395 - accuracy: 0.6154\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.9231\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4033 - accuracy: 0.9231\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6418 - accuracy: 0.9231\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3913 - accuracy: 0.9231\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9212 - accuracy: 0.9231\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0791 - accuracy: 0.7692\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2618 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9064 - accuracy: 0.9231\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8677 - accuracy: 0.9231\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.9231\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9231\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f7914400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3575 - accuracy: 0.5714\n",
            "Model: \"sequential_88\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_528 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_529 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_352 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_530 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_353 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_531 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_354 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_532 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_355 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_533 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4621 - accuracy: 0.3846\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.5471 - accuracy: 0.2308\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 22.3809 - accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.9926 - accuracy: 0.6154\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.3459 - accuracy: 0.2308\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0349 - accuracy: 0.6154\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6524 - accuracy: 0.6154\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6712 - accuracy: 0.2308\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.7318 - accuracy: 0.1538\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4698 - accuracy: 0.6154\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1444 - accuracy: 0.6154\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0434 - accuracy: 0.6154\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7606 - accuracy: 0.6154\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8937 - accuracy: 0.2308\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8555 - accuracy: 0.6154\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7785 - accuracy: 0.7692\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8932 - accuracy: 0.3077\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0737 - accuracy: 0.6154\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1676 - accuracy: 0.6154\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3585 - accuracy: 0.3077\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2247 - accuracy: 0.8462\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2319 - accuracy: 0.7692\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.7692\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.9231\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0292 - accuracy: 0.6154\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.8462\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.8462\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8462\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.9231\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.9231\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2589 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2039 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f4d61f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9949 - accuracy: 0.4286\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_534 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_535 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_356 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_536 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_357 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_537 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_358 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_538 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_359 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_539 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4844 - accuracy: 0.3571\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7533 - accuracy: 0.4286\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7736 - accuracy: 0.2857\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 48.2218 - accuracy: 0.2857\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 22.3102 - accuracy: 0.2857\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9413 - accuracy: 0.2857\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0592 - accuracy: 0.3571\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7686 - accuracy: 0.2857\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9122 - accuracy: 0.4286\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4174 - accuracy: 0.4286\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0255 - accuracy: 0.5714\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6154 - accuracy: 0.2857\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6818 - accuracy: 0.2857\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0907 - accuracy: 0.2857\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1903 - accuracy: 0.2857\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9305 - accuracy: 0.4286\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5724 - accuracy: 0.4286\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7863 - accuracy: 0.4286\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2965 - accuracy: 0.4286\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1359 - accuracy: 0.3571\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4572 - accuracy: 0.2857\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4013 - accuracy: 0.2857\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9232 - accuracy: 0.6429\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7098 - accuracy: 0.3571\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6709 - accuracy: 0.7143\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8995 - accuracy: 0.7143\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0913 - accuracy: 0.2857\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7774 - accuracy: 0.7143\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7149 - accuracy: 0.4286\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7390 - accuracy: 0.7857\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8142 - accuracy: 0.7143\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1223 - accuracy: 0.7143\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2750 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.7857\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2200 - accuracy: 0.7143\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9286\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.9286\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.9286\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f953fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7524 - accuracy: 0.3333\n",
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_540 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_541 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_360 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_542 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_361 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_543 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_362 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_544 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_363 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_545 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5664 - accuracy: 0.4615\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.8089 - accuracy: 0.4615\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.4048 - accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.3583 - accuracy: 0.4615\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 16.1119 - accuracy: 0.6154\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 22.9198 - accuracy: 0.4615\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 31.0818 - accuracy: 0.4615\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 27.8734 - accuracy: 0.4615\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.5042 - accuracy: 0.8462\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.7957 - accuracy: 0.6154\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 17.5006 - accuracy: 0.4615\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.5904 - accuracy: 0.5385\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.7142 - accuracy: 0.4615\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.5578 - accuracy: 0.5385\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.2458 - accuracy: 0.4615\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 29.9924 - accuracy: 0.2308\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.8220 - accuracy: 0.3077\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 22.0623 - accuracy: 0.2308\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.3239 - accuracy: 0.3846\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.7669 - accuracy: 0.4615\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7066 - accuracy: 0.3846\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8957 - accuracy: 0.7692\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5863 - accuracy: 0.4615\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.5366 - accuracy: 0.2308\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3184 - accuracy: 0.7692\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0540 - accuracy: 0.4615\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1851 - accuracy: 0.4615\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.1886 - accuracy: 0.4615\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.5220 - accuracy: 0.3846\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.1646 - accuracy: 0.1538\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3150 - accuracy: 0.6154\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2974 - accuracy: 0.3846\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.8849 - accuracy: 0.4615\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6287 - accuracy: 0.5385\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1197 - accuracy: 0.5385\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6061 - accuracy: 0.5385\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3023 - accuracy: 0.6154\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9924 - accuracy: 0.4615\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0956 - accuracy: 0.6154\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7629 - accuracy: 0.4615\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4856 - accuracy: 0.5385\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2368 - accuracy: 0.4615\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1481 - accuracy: 0.5385\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5203 - accuracy: 0.6923\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7836 - accuracy: 0.5385\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7900 - accuracy: 0.5385\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8311 - accuracy: 0.6154\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6188 - accuracy: 0.6154\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5381 - accuracy: 0.6154\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5585 - accuracy: 0.6154\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f398c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6162 - accuracy: 0.4286\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_546 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_547 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_364 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_548 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_365 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_549 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_366 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_550 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_367 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_551 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6664 - accuracy: 0.2308\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.4621 - accuracy: 0.4615\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 33.1199 - accuracy: 0.3077\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.6790 - accuracy: 0.3846\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 32.8070 - accuracy: 0.3077\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 26.3721 - accuracy: 0.3846\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 20.1678 - accuracy: 0.5385\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 26.8576 - accuracy: 0.5385\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 38.7782 - accuracy: 0.4615\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 27.3277 - accuracy: 0.4615\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 24.7801 - accuracy: 0.3077\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 35.5237 - accuracy: 0.5385\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 18.9217 - accuracy: 0.4615\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.1375 - accuracy: 0.4615\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.6478 - accuracy: 0.4615\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3498 - accuracy: 0.6154\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.8998 - accuracy: 0.3846\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.9648 - accuracy: 0.3077\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.7152 - accuracy: 0.3077\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 23.2142 - accuracy: 0.3077\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.7994 - accuracy: 0.3846\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 14.2802 - accuracy: 0.3077\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.6746 - accuracy: 0.2308\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0875 - accuracy: 0.3846\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.1399 - accuracy: 0.4615\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.8507 - accuracy: 0.5385\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.8421 - accuracy: 0.3846\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.7002 - accuracy: 0.3846\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.2809 - accuracy: 0.6154\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.2115 - accuracy: 0.5385\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0701 - accuracy: 0.5385\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3161 - accuracy: 0.5385\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3945 - accuracy: 0.6154\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.9358 - accuracy: 0.5385\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3700 - accuracy: 0.6154\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3546 - accuracy: 0.4615\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2121 - accuracy: 0.4615\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6565 - accuracy: 0.4615\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.7823 - accuracy: 0.3846\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.3165 - accuracy: 0.1538\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9418 - accuracy: 0.6923\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.1560 - accuracy: 0.5385\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7746 - accuracy: 0.4615\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1241 - accuracy: 0.4615\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8960 - accuracy: 0.4615\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2549 - accuracy: 0.3846\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.0818 - accuracy: 0.3846\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.5901 - accuracy: 0.3846\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7784 - accuracy: 0.6154\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0314 - accuracy: 0.6154\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f2d69730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1157 - accuracy: 0.4286\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_552 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_553 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_368 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_554 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_369 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_555 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_370 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_556 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_371 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_557 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8584 - accuracy: 0.2143\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.3325 - accuracy: 0.2143\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7499 - accuracy: 0.3571\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 21.6174 - accuracy: 0.2143\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.7065 - accuracy: 0.3571\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.0257 - accuracy: 0.5714\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 21.6730 - accuracy: 0.2143\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.1513 - accuracy: 0.3571\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 32.3615 - accuracy: 0.1429\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 21.1984 - accuracy: 0.2857\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.2018 - accuracy: 0.2857\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 19.7883 - accuracy: 0.3571\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.8294 - accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.0823 - accuracy: 0.6429\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 13.7244 - accuracy: 0.2857\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.8070 - accuracy: 0.0714\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.9234 - accuracy: 0.2143\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8210 - accuracy: 0.4286\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3473 - accuracy: 0.3571\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.1665 - accuracy: 0.2857\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7325 - accuracy: 0.2857\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0296 - accuracy: 0.3571\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5342 - accuracy: 0.3571\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 12.1776 - accuracy: 0.3571\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.1482 - accuracy: 0.2143\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3487 - accuracy: 0.2857\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7749 - accuracy: 0.0714\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9355 - accuracy: 0.2857\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9980 - accuracy: 0.2857\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9703 - accuracy: 0.2857\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4678 - accuracy: 0.2857\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4940 - accuracy: 0.3571\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6775 - accuracy: 0.2857\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2152 - accuracy: 0.6429\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.5843 - accuracy: 0.4286\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2603 - accuracy: 0.2143\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7456 - accuracy: 0.2143\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5998 - accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4986 - accuracy: 0.3571\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4004 - accuracy: 0.2857\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7292 - accuracy: 0.4286\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5406 - accuracy: 0.5714\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0960 - accuracy: 0.4286\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9139 - accuracy: 0.2143\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0198 - accuracy: 0.2143\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6981 - accuracy: 0.2143\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4093 - accuracy: 0.2857\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9670 - accuracy: 0.3571\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9951 - accuracy: 0.2143\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3506 - accuracy: 0.5714\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6f9590840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9026 - accuracy: 0.8333\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_558 (Dense)            (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_559 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_372 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_560 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_373 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_561 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_374 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_562 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_375 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_563 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 25,340,995\n",
            "Trainable params: 25,340,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 4.0708 - accuracy: 0.3500\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 22.3803 - accuracy: 0.2000\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 18.1974 - accuracy: 0.3500\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 24.6168 - accuracy: 0.4500\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 28.6777 - accuracy: 0.2000\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 28.2170 - accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 19.1644 - accuracy: 0.3500\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 35.5742 - accuracy: 0.3500\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 16.7062 - accuracy: 0.2500\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 21.0189 - accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 13.3990 - accuracy: 0.3000\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 14.7152 - accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 11.2597 - accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 12.3452 - accuracy: 0.3000\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 9.5601 - accuracy: 0.3500\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 6.7334 - accuracy: 0.3500\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 11.1506 - accuracy: 0.1500\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 6.3501 - accuracy: 0.4500\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 4.6319 - accuracy: 0.5500\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 4.6892 - accuracy: 0.5500\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 4.7641 - accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 4.6145 - accuracy: 0.2500\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 5.7346 - accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 5.0435 - accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.4106 - accuracy: 0.4500\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.1561 - accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 4.2974 - accuracy: 0.3500\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.8033 - accuracy: 0.2500\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 2.1127 - accuracy: 0.5500\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 2.9144 - accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.3360 - accuracy: 0.6500\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.3651 - accuracy: 0.5500\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.7754 - accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.5691 - accuracy: 0.3500\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.6335 - accuracy: 0.6000\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.7990 - accuracy: 0.3500\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.8903 - accuracy: 0.5500\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.1693 - accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.9654 - accuracy: 0.6500\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1.8117 - accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.8948 - accuracy: 0.7000\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.9495 - accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.7266 - accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.9554 - accuracy: 0.5500\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.2893 - accuracy: 0.6500\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.6834 - accuracy: 0.7000\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.7992 - accuracy: 0.5500\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.3178 - accuracy: 0.7000\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.5932 - accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.3720 - accuracy: 0.4500\n",
            "Best score is: 0.6111111144224802 using {'optimizer': 'adam', 'momentum': 0.2, 'learn_rate': 0.001, 'dropout_rate_opts': 0.2, 'batch_size': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3DsCeOSfgD1"
      },
      "source": [
        "**Basic Artificial Neural Network Architecture Building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUdyT4zEvPXC",
        "outputId": "373f181e-d210-4a45-815e-cc5c115a6c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "model = Sequential()   \n",
        "model.add(Dense(96, input_shape=(49152,), activation=\"relu\"))\n",
        "keras.layers.BatchNormalization()             \n",
        "model.add(Dense(64, activation=\"relu\",kernel_regularizer=regularizers.l2(0.001))) \n",
        "keras.layers.BatchNormalization()\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(32, activation=\"relu\"))  \n",
        "keras.layers.BatchNormalization()  \n",
        "model.add(Dropout(0.2)) \n",
        "#model.add(Dense(128, activation=\"relu\"))  \n",
        "#keras.layers.BatchNormalization()  \n",
        "#model.add(Dropout(0.2)) \n",
        "#model.add(Dense(64, activation=\"relu\"))\n",
        "#keras.layers.BatchNormalization()\n",
        "#model.add(Dropout(0.2))      \n",
        "#model.add(Dense(32, activation=\"relu\"))  \n",
        "#keras.layers.BatchNormalization()  \n",
        "#model.add(Dropout(0.2))      \n",
        "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 96)                4718688   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                6208      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 4,727,075\n",
            "Trainable params: 4,727,075\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeDz6DtDfuQ5"
      },
      "source": [
        "**ANN Model fitting & Evaluating of test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DduCiMctwMjm"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "#opt = Adam(lr=0.001)   # Stochastic Gradient Descent (SGD) optimizer\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yirEmO2bw3h4",
        "outputId": "12439c68-94e8-4caf-ada8-db08970485b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"ANN_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "history=model.fit(train_x,train_y,batch_size =40,epochs=70,verbose=1,validation_data=(eval_x, eval_y),callbacks=[checkpoint,early],shuffle=True)\n",
        "history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.1873 - accuracy: 0.5000\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.40000, saving model to ANN_1.h5\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 6.5454 - accuracy: 0.4875 - val_loss: 4.9380 - val_accuracy: 0.4000\n",
            "Epoch 2/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8488 - accuracy: 0.4500\n",
            "Epoch 00002: val_accuracy improved from 0.40000 to 0.60000, saving model to ANN_1.h5\n",
            "2/2 [==============================] - 1s 535ms/step - loss: 5.1209 - accuracy: 0.4375 - val_loss: 4.5424 - val_accuracy: 0.6000\n",
            "Epoch 3/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 10.8663 - accuracy: 0.3250\n",
            "Epoch 00003: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3055 - accuracy: 0.4000 - val_loss: 8.1127 - val_accuracy: 0.4000\n",
            "Epoch 4/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7876 - accuracy: 0.4750\n",
            "Epoch 00004: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 7.4682 - accuracy: 0.4125 - val_loss: 8.1348 - val_accuracy: 0.4000\n",
            "Epoch 5/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8443 - accuracy: 0.4500\n",
            "Epoch 00005: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 6.4133 - accuracy: 0.4500 - val_loss: 2.8279 - val_accuracy: 0.4000\n",
            "Epoch 6/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0690 - accuracy: 0.4000\n",
            "Epoch 00006: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 5.2727 - accuracy: 0.3500 - val_loss: 2.0147 - val_accuracy: 0.4000\n",
            "Epoch 7/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4826 - accuracy: 0.3500\n",
            "Epoch 00007: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.9943 - accuracy: 0.3625 - val_loss: 3.4412 - val_accuracy: 0.4000\n",
            "Epoch 8/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5454 - accuracy: 0.4250\n",
            "Epoch 00008: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.5487 - accuracy: 0.4125 - val_loss: 1.8449 - val_accuracy: 0.4000\n",
            "Epoch 9/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4535 - accuracy: 0.5000\n",
            "Epoch 00009: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.2308 - accuracy: 0.4625 - val_loss: 1.4391 - val_accuracy: 0.6000\n",
            "Epoch 10/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6748 - accuracy: 0.5750\n",
            "Epoch 00010: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.3710 - accuracy: 0.5375 - val_loss: 1.5877 - val_accuracy: 0.6000\n",
            "Epoch 11/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.1497 - accuracy: 0.5500\n",
            "Epoch 00011: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.0549 - accuracy: 0.4125 - val_loss: 0.9187 - val_accuracy: 0.6000\n",
            "Epoch 12/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.2210 - accuracy: 0.5500\n",
            "Epoch 00012: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.2959 - accuracy: 0.5000 - val_loss: 1.6304 - val_accuracy: 0.6000\n",
            "Epoch 13/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.5969 - accuracy: 0.7000\n",
            "Epoch 00013: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.9901 - accuracy: 0.6250 - val_loss: 1.5204 - val_accuracy: 0.6000\n",
            "Epoch 14/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.5785 - accuracy: 0.6500\n",
            "Epoch 00014: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.6506 - accuracy: 0.6250 - val_loss: 0.7443 - val_accuracy: 0.6000\n",
            "Epoch 15/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.2543 - accuracy: 0.6250\n",
            "Epoch 00015: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.2567 - accuracy: 0.6500 - val_loss: 0.8856 - val_accuracy: 0.6000\n",
            "Epoch 16/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.3623 - accuracy: 0.6500\n",
            "Epoch 00016: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.3104 - accuracy: 0.6375 - val_loss: 1.2278 - val_accuracy: 0.6000\n",
            "Epoch 17/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0238 - accuracy: 0.6250\n",
            "Epoch 00017: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8643 - accuracy: 0.6375 - val_loss: 1.5208 - val_accuracy: 0.6000\n",
            "Epoch 18/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.9792 - accuracy: 0.7250\n",
            "Epoch 00018: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1231 - accuracy: 0.7000 - val_loss: 1.6128 - val_accuracy: 0.6000\n",
            "Epoch 19/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8043 - accuracy: 0.7000\n",
            "Epoch 00019: val_accuracy did not improve from 0.60000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0704 - accuracy: 0.6500 - val_loss: 1.2749 - val_accuracy: 0.6000\n",
            "Epoch 20/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6092 - accuracy: 0.8000\n",
            "Epoch 00020: val_accuracy improved from 0.60000 to 0.80000, saving model to ANN_1.h5\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.7617 - accuracy: 0.7625 - val_loss: 0.7210 - val_accuracy: 0.8000\n",
            "Epoch 21/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8527 - accuracy: 0.7000\n",
            "Epoch 00021: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8689 - accuracy: 0.7125 - val_loss: 0.4978 - val_accuracy: 0.8000\n",
            "Epoch 22/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7974 - accuracy: 0.7000\n",
            "Epoch 00022: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7452 - accuracy: 0.7250 - val_loss: 0.6617 - val_accuracy: 0.8000\n",
            "Epoch 23/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4912 - accuracy: 0.8750\n",
            "Epoch 00023: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5632 - accuracy: 0.8375 - val_loss: 0.7748 - val_accuracy: 0.6000\n",
            "Epoch 24/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0244 - accuracy: 0.6500\n",
            "Epoch 00024: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8834 - accuracy: 0.7375 - val_loss: 0.9293 - val_accuracy: 0.6000\n",
            "Epoch 25/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4105 - accuracy: 0.8750\n",
            "Epoch 00025: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5160 - accuracy: 0.8250 - val_loss: 1.0588 - val_accuracy: 0.6000\n",
            "Epoch 26/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5890 - accuracy: 0.8500\n",
            "Epoch 00026: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5520 - accuracy: 0.8375 - val_loss: 1.1079 - val_accuracy: 0.6000\n",
            "Epoch 27/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7557 - accuracy: 0.7500\n",
            "Epoch 00027: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6574 - accuracy: 0.7500 - val_loss: 0.9439 - val_accuracy: 0.6000\n",
            "Epoch 28/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3826 - accuracy: 0.8500\n",
            "Epoch 00028: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3616 - accuracy: 0.8500 - val_loss: 0.5800 - val_accuracy: 0.8000\n",
            "Epoch 29/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6704 - accuracy: 0.8250\n",
            "Epoch 00029: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5692 - accuracy: 0.8500 - val_loss: 0.9499 - val_accuracy: 0.6000\n",
            "Epoch 30/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2953 - accuracy: 0.9250\n",
            "Epoch 00030: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3966 - accuracy: 0.8750 - val_loss: 1.2215 - val_accuracy: 0.6000\n",
            "Epoch 31/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2051 - accuracy: 0.9500\n",
            "Epoch 00031: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3052 - accuracy: 0.9000 - val_loss: 0.9421 - val_accuracy: 0.6000\n",
            "Epoch 32/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3804 - accuracy: 0.8250\n",
            "Epoch 00032: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4587 - accuracy: 0.7875 - val_loss: 1.0415 - val_accuracy: 0.6000\n",
            "Epoch 33/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4172 - accuracy: 0.9000\n",
            "Epoch 00033: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4525 - accuracy: 0.8500 - val_loss: 0.9531 - val_accuracy: 0.6000\n",
            "Epoch 34/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3503 - accuracy: 0.8750\n",
            "Epoch 00034: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4892 - accuracy: 0.8375 - val_loss: 1.5876 - val_accuracy: 0.6000\n",
            "Epoch 35/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5349 - accuracy: 0.8500\n",
            "Epoch 00035: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4606 - accuracy: 0.8750 - val_loss: 1.1674 - val_accuracy: 0.6000\n",
            "Epoch 36/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2145 - accuracy: 0.9500\n",
            "Epoch 00036: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2455 - accuracy: 0.9375 - val_loss: 0.8991 - val_accuracy: 0.8000\n",
            "Epoch 37/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3123 - accuracy: 0.8750\n",
            "Epoch 00037: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3483 - accuracy: 0.8875 - val_loss: 0.9593 - val_accuracy: 0.8000\n",
            "Epoch 38/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1836 - accuracy: 0.9500\n",
            "Epoch 00038: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1618 - accuracy: 0.9625 - val_loss: 1.4473 - val_accuracy: 0.6000\n",
            "Epoch 39/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1429 - accuracy: 0.9750\n",
            "Epoch 00039: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1931 - accuracy: 0.9625 - val_loss: 1.4089 - val_accuracy: 0.6000\n",
            "Epoch 40/70\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1365 - accuracy: 0.9500\n",
            "Epoch 00040: val_accuracy did not improve from 0.80000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1463 - accuracy: 0.9625 - val_loss: 0.7343 - val_accuracy: 0.8000\n",
            "Epoch 00040: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa3db31eac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwWIbcAOgIhU"
      },
      "source": [
        "**ANN mdel accuracy & loss visualtion on Train & Validation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn9Dp4GqMLKr",
        "outputId": "549f957b-c1be-44ff-b7a9-d1b32378c2de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "#history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ukaEbIwgZwG"
      },
      "source": [
        "**As we can see the ANN model is little overfiiting on validation dataset. So, to perform a better architecture on Image Dataset I have introduced Convolutional Neural Network in my next colab notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV1k2WzjOfkJ",
        "outputId": "136afb22-a9d6-4769-ab6b-17a89bfd44cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pRuMLg9f81b"
      },
      "source": [
        "**Evaluation of ANN model on test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQfhdAIEo2ix",
        "outputId": "49b397bf-5d8c-43a8-b44c-0d361936333e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Evaluating the model for convnet\n",
        "score = model.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.9325188398361206\n",
            "Test accuracy: 0.800000011920929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvliaBRyfzDL"
      },
      "source": [
        "**Multi-Class Confusion Matrix for Car,Bike and Random Images after running ANN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBApMpV9o6DG",
        "outputId": "a08a93ca-95ba-434b-8da3-b308f0ab32b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "Y_pred = model.predict(test_x)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       0.50      1.00      0.67         2\n",
            "  class 1(bike)       0.80      1.00      0.89         4\n",
            "class 2(random)       1.00      0.67      0.80         9\n",
            "\n",
            "       accuracy                           0.80        15\n",
            "      macro avg       0.77      0.89      0.79        15\n",
            "   weighted avg       0.88      0.80      0.81        15\n",
            "\n",
            "[[2 0 0]\n",
            " [0 4 0]\n",
            " [2 1 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}